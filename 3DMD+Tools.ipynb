{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import menpo.io as mio\n",
    "#import scipy.io as sio\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import errno\n",
    "#import menpo.shape\n",
    "#%matplotlib inline\n",
    "import re\n",
    "from shutil import copyfile\n",
    "import fnmatch\n",
    "from PIL import Image\n",
    "import json\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os.path\n",
    "import errno\n",
    "import re\n",
    "from shutil import copyfile\n",
    "import fnmatch\n",
    "#from PIL import Image\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "root = '10_04_2017'\n",
    "# Relative path for the exporting directory\n",
    "exportdirectory_path='\\\\\\\\fs-vol-phoebe.doc.ic.ac.uk\\\\phoebe\\\\NEW_3DMD'\n",
    "# Absolute paths for calibrations and mstereo.ini\n",
    "calibations_path='\\\\\\\\fs-vol-phoebe.doc.ic.ac.uk\\\\phoebe\\\\3DMD_SCIENCE_MUSEUM\\\\calibrations'\n",
    "mstereo_path='\\\\\\\\fs-vol-phoebe.doc.ic.ac.uk\\\\phoebe\\\\3DMD_SCIENCE_MUSEUM\\\\Mstereo\\\\mstereo_default.ini'\n",
    "#  Absolyte path to back up all the old json files,\n",
    "#  old json files are also backed up in the same folder changing just the extension\n",
    "backupjson_path='backupjson'\n",
    "\n",
    "num_images=0\n",
    "num_imgs=[]\n",
    "ilevel=1\n",
    "num_copied=0 \n",
    "\n",
    "for path, dirs, files in os.walk(root):\n",
    "    if ilevel==1:\n",
    "        subjects=dirs\n",
    "        folder_name=path.split('/')[-1]\n",
    "        print(path,dirs,files,'folder name is',folder_name)    \n",
    "    ilevel=ilevel+1\n",
    "    for name in files:\n",
    "        if fnmatch.fnmatch(name, '*.json') and len(name.split('.'))==2:\n",
    "            \n",
    "            num_images=num_images+1\n",
    "            source_filename=''.join([path,'/',name])\n",
    "            dest_filename=''.join([path,'/',name.split('.')[0],'.bak'])\n",
    "            dest_filename2=''.join([backupjson_path,'/',folder_name,'/',name])\n",
    "            if not os.path.exists(os.path.dirname(dest_filename2)):\n",
    "                try:\n",
    "                    os.makedirs(os.path.dirname(dest_filename2))\n",
    "                except OSError as exc: # Guard against race condition\n",
    "                    if exc.errno != errno.EEXIST:\n",
    "                        raise\n",
    "            print(dest_filename2)\n",
    "            if os.path.isfile(source_filename):\n",
    "                copyfile(source_filename, dest_filename)\n",
    "                copyfile(source_filename, dest_filename2)\n",
    "                print(source_filename,' copied to ',dest_filename)\n",
    "                num_copied=num_copied+1\n",
    "            with open(path+'/'+name) as data_file:    \n",
    "                data = json.load(data_file)\n",
    "                data_file.close() # Close the JSON file\n",
    "\n",
    "            data[\"exportdirectory\"] = ''.join([exportdirectory_path,'\\\\',root]) \n",
    "            data[\"exportmstereoini\"]=mstereo_path\n",
    "            data[\"exporttkadir\"]=''.join([calibations_path,'\\\\', data[\"exporttkadir\"].split('/')[-1]])  \n",
    "            print(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Export thumbnails for annoation </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "root = '/vol/phoebe/3DMD_SCIENSE_MUSEUM/15_06_2017/'\n",
    "# root = '/media/ap112/My Passport/22_06_2017/'\n",
    "dest='/media/ap112/C4184698184688FE/Dropbox/PostDoc/'\n",
    "\n",
    "num_images=0\n",
    "num_imgs=[]\n",
    "size= 640, 480\n",
    "ilevel=1\n",
    "num_bmp=0\n",
    "num_obj=0\n",
    "\n",
    "# if os.direxists(os.path.join(os.getcwd()), 'new_folder'))\n",
    "for path, dirs, files in os.walk(root):\n",
    "    if ilevel==1:\n",
    "        subjects=dirs\n",
    "        folder_name=path.split('/')[-2]\n",
    "        print(path,dirs,files,'folder name is',folder_name)        \n",
    "    ilevel=ilevel+1\n",
    "    for name in files:\n",
    "        if fnmatch.fnmatch(name, '*.bmp'):\n",
    "            num_images=num_images+1\n",
    "    if 'meshes' in path.split('/')[-1]:\n",
    "        for name in files:\n",
    "#             e = time()\n",
    "            if fnmatch.fnmatch(name, '*.bmp'):\n",
    "                \n",
    "                tmp_name=name.split('/')\n",
    "#                 old_name=new_name[0]\n",
    "                new_name=tmp_name[-1].split('.')\n",
    "                new_path=dest+folder_name+'/'+new_name[0]\n",
    "#                 print(new_path,'Old name is' ,old_name,new_name)\n",
    "                if not os.path.exists(new_path):\n",
    "                    os.makedirs(new_path)\n",
    "                im = Image.open(path+'/'+name)\n",
    "                im.thumbnail(size, Image.ANTIALIAS)\n",
    "                \n",
    "                im.save(new_path+'/'+new_name[0]+'.'+new_name[1]+'.jpg',quality=90)\n",
    "                num_bmp=num_bmp+1\n",
    "#                 print(time() - e)\n",
    "            if fnmatch.fnmatch(name, '*.obj'):\n",
    "                num_obj=num_obj+1\n",
    "#             if old_name != new_name[0]:\n",
    "#                 print(old_name+' has just finished')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Change json files of a session</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '10_04_2017'\n",
    "# Relative path for the exporting directory\n",
    "exportdirectory_path='\\\\\\\\fs-vol-phoebe.doc.ic.ac.uk\\\\phoebe\\\\NEW_3DMD'\n",
    "# Absolute paths for calibrations and mstereo.ini\n",
    "calibations_path='\\\\\\\\fs-vol-phoebe.doc.ic.ac.uk\\\\phoebe\\\\3DMD_SCIENCE_MUSEUM\\\\calibrations'\n",
    "mstereo_path='\\\\\\\\fs-vol-phoebe.doc.ic.ac.uk\\\\phoebe\\\\3DMD_SCIENCE_MUSEUM\\\\Mstereo\\\\mstereo_default.ini'\n",
    "#  Absolyte path to back up all the old json files,\n",
    "#  old json files are also backed up in the same folder changing just the extension\n",
    "backupjson_path='backupjson'\n",
    "\n",
    "num_images=0\n",
    "num_imgs=[]\n",
    "ilevel=1\n",
    "num_copied=0 \n",
    "\n",
    "for path, dirs, files in os.walk(root):\n",
    "    if ilevel==1:\n",
    "        subjects=dirs\n",
    "        folder_name=path.split('/')[-1]\n",
    "        print(path,dirs,files,'folder name is',folder_name)    \n",
    "    ilevel=ilevel+1\n",
    "    for name in files:\n",
    "        if fnmatch.fnmatch(name, '*.json') and len(name.split('.'))==2:\n",
    "            \n",
    "            num_images=num_images+1\n",
    "            source_filename=''.join([path,'/',name])\n",
    "            dest_filename=''.join([path,'/',name.split('.')[0],'.bak'])\n",
    "            dest_filename2=''.join([backupjson_path,'/',folder_name,'/',name])\n",
    "            if not os.path.exists(os.path.dirname(dest_filename2)):\n",
    "                try:\n",
    "                    os.makedirs(os.path.dirname(dest_filename2))\n",
    "                except OSError as exc: # Guard against race condition\n",
    "                    if exc.errno != errno.EEXIST:\n",
    "                        raise\n",
    "            print(dest_filename2)\n",
    "            if os.path.isfile(source_filename):\n",
    "                copyfile(source_filename, dest_filename)\n",
    "                copyfile(source_filename, dest_filename2)\n",
    "                print(source_filename,' copied to ',dest_filename)\n",
    "                num_copied=num_copied+1\n",
    "            with open(path+'/'+name) as data_file:    \n",
    "                data = json.load(data_file)\n",
    "                data_file.close() # Close the JSON file\n",
    "\n",
    "            data[\"exportdirectory\"] = ''.join([exportdirectory_path,'\\\\',root]) \n",
    "            data[\"exportmstereoini\"]=mstereo_path\n",
    "            data[\"exporttkadir\"]=''.join([calibations_path,'\\\\', data[\"exporttkadir\"].split('/')[-1]])  \n",
    "#            print(data)\n",
    "## Save our changes to JSON file\n",
    "            if name=='00001.json':\n",
    "                  with open(source_filename, 'w') as outfile:  \n",
    "                      json.dump(data, outfile)\n",
    "                      outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Functions used to handle Google Spreadsheet</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use creds to create a client to interact with the Google Drive API\n",
    "def read_google_sheets(spreadsheet_name):\n",
    "    scope = ['https://spreadsheets.google.com/feeds']\n",
    "    creds = ServiceAccountCredentials.from_json_keyfile_name('client_secret.json', scope)\n",
    "    client = gspread.authorize(creds)\n",
    " \n",
    "    # Find a workbook by name and open the first sheet\n",
    "    # Make sure you use the right name here.\n",
    "    sheet = client.open(spreadsheet_name).sheet1\n",
    " \n",
    "    # Extract and print all of the values\n",
    "    list_of_hashes = sheet.get_all_records()\n",
    "    list_of_hashes=list(filter(lambda x: x['Id']!='', list_of_hashes))\n",
    "    # a = [x for x in new_list if x['Id'] != 250]\n",
    "    return list_of_hashes\n",
    "\n",
    "def searchdate(search_year, people):\n",
    "        return [element for element in people if datetime.strptime(element['DateBirth'],'%d/%m/%Y').year<search_year and element['Ethnicity']=='White' ]\n",
    "\n",
    "def searchidn(idn, people):\n",
    "    return [element for element in people if element['Gender'] == idn]\n",
    "\n",
    "def copy_obj_bmp2jpg_files(root_path,dest_path,list_of_people):\n",
    "    exist_lists=[]\n",
    "    for person in list_of_people:\n",
    "    #Transform the date to the one that is used for folders, namely dd_mm_yyyy\n",
    "        if person['Id']<250:\n",
    "            dt=datetime.strptime(person['Timestamp'],'%d/%m/%Y')\n",
    "        else:\n",
    "            dt=datetime.strptime(person['Timestamp'],'%d/%m/%Y %X')\n",
    "        if dt.day<10:\n",
    "            tmpday=''.join(['0',str(dt.day)])\n",
    "        else:\n",
    "            tmpday=str(dt.day)\n",
    "        date_session=''.join([tmpday,'_0',str(dt.month),'_',str(dt.year)])\n",
    "        #Check if  there is zero padding\n",
    "        if  os.path.exists(os.path.dirname(''.join([root_path,date_session,'/',str(element['Id'])]))):\n",
    "            zero_padding=''\n",
    "        elif  os.path.exists(os.path.dirname(''.join([root_path,date_session,'/0',str(element['Id'])]))):\n",
    "            zero_padding='0'\n",
    "        elif  os.path.exists(os.path.dirname(''.join([root_path,date_session,'/00',str(element['Id'])]))):\n",
    "            zero_padding='00'\n",
    "        elif  os.path.exists(os.path.dirname(''.join([root_path,date_session,'/000',str(element['Id'])]))):\n",
    "            zero_padding='000'\n",
    "        elif  os.path.exists(os.path.dirname(''.join([root_path,date_session,'/0000',str(element['Id'])]))):\n",
    "            zero_padding='0000'\n",
    "        else: \n",
    "            print(''.join([date_session,'/',str(element['Id'])]),'cannot be found')\n",
    "        fileid=''.join([zero_padding,str(element['Id'])])\n",
    "            \n",
    "#         folder=''.join([tmpday,'_0',str(dt.month),'_',str(dt.year),'/', fileid])\n",
    "    \n",
    "        source_path=''.join([root_path,date_session,'/',fileid,'/meshes/'])\n",
    "        if os.path.exists(os.path.dirname(source_path)):\n",
    "#         print(source_path, 'exists')\n",
    "            filename=''.join([fileid,'.000001'])   \n",
    "            bmpfile=''.join([filename,'.bmp'])\n",
    "            objfile=''.join([filename,'.obj'])\n",
    "            if os.path.isfile(source_path+bmpfile):\n",
    "#                           print(source_path+bmpfiles)\n",
    "#                           print(source_path+objfiles)\n",
    "                          copyfile(source_path+objfile, dest_path+objfile)\n",
    "                          im = Image.open(source_path+bmpfile)\n",
    "                          im.save(dest_path+filename+'.jpg',quality=90)    \n",
    "            exist_lists.append(source_path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=read_google_sheets(spreadsheet_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223\n"
     ]
    }
   ],
   "source": [
    "print(len(above60white))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "above60white=searchdate(1967,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List has been read\n",
      "10_04_2017/4444 cannot be found\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'zero_padding' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-252-4cd922b6368b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'List has been read'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mabove60white\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msearchdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1967\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlist_of_hashes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mcopy_obj_bmp2jpg_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdest_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mabove60white\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-251-4411e0c51a74>\u001b[0m in \u001b[0;36mcopy_obj_bmp2jpg_files\u001b[0;34m(root_path, dest_path, list_of_people)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdate_session\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'cannot be found'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mfileid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mzero_padding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m#         folder=''.join([tmpday,'_0',str(dt.month),'_',str(dt.year),'/', fileid])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'zero_padding' referenced before assignment"
     ]
    }
   ],
   "source": [
    "root_path='/vol/phoebe/3DMD_SCIENCE_MUSEUM/'\n",
    "dest_path='/data/Dropbox/Dropbox/Ageover50b/'\n",
    "spreadsheet_name= \"Copy Museum data\"\n",
    "\n",
    "list_of_hashes=read_google_sheets(spreadsheet_name)\n",
    "print('List has been read')\n",
    "above60white=searchdate(1967,list_of_hashes)\n",
    "copy_obj_bmp2jpg_files(root_path,dest_path,above60white)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Export thumbnails by 4G<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import menpo.io as mio\n",
    "\n",
    "from menpo.visualize import print_progress\n",
    "from pathlib import Path\n",
    "\n",
    "def process_image(im):\n",
    "    im = im.rescale_to_diagonal(700)\n",
    "    subject_id = im.path.stem.split('.')[0]\n",
    "    path =  Path('tmp') / subject_id / im.path.with_suffix('.jpg').name\n",
    "    \n",
    "    try:\n",
    "        mio.export_image(im, path, overwrite=True)\n",
    "    except:\n",
    "        path.parent.mkdir(exist_ok=True, parents=True)\n",
    "        mio.export_image(im, path)\n",
    "\n",
    "# for im in print_progress(mio.import_images('/media/ap112/Seagate Expansion Drive/11_06_2017/**/meshes/*.bmp')):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "pool = Pool(4)\n",
    "\n",
    "pool.map_async(process_image, mio.import_images('/media/ap112/Seagate Expansion Drive/11_06_2017/**/meshes/*.bmp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pool.map_async()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
